{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "from dnn_training.dataset_ak import *\n",
    "from dnn_training.dataset_torch import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ak = loadDataset_ak(\"/grid_mnt/data_cms_upgrade/cuisset/supercls/alessandro_electrons/supercls-v13/superclsDumper_1.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_zipped = zipDataset(dataset_ak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[217,\n",
       " 16,\n",
       " 22,\n",
       " 252,\n",
       " 130,\n",
       " 252,\n",
       " 116,\n",
       " 157,\n",
       " 117,\n",
       " 386,\n",
       " ...,\n",
       " 27,\n",
       " 145,\n",
       " 58,\n",
       " 24,\n",
       " 696,\n",
       " 156,\n",
       " 88,\n",
       " 85,\n",
       " 63]\n",
       "------------------\n",
       "type: 100 * ?int64</pre>"
      ],
      "text/plain": [
       "<Array [217, 16, 22, 252, 130, ..., 696, 156, 88, 85, 63] type='100 * ?int64'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.argmax(d_zipped.feature_seedPt, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[607,\n",
       " 631,\n",
       " 751,\n",
       " 2608,\n",
       " 1966,\n",
       " 739,\n",
       " 2052,\n",
       " 767,\n",
       " 688,\n",
       " 1875,\n",
       " ...,\n",
       " 751,\n",
       " 580,\n",
       " 527,\n",
       " 1866,\n",
       " 737,\n",
       " 2334,\n",
       " 682,\n",
       " 634,\n",
       " 771]\n",
       "-------------------\n",
       "type: 100 * ?uint32</pre>"
      ],
      "text/plain": [
       "<Array [607, 631, 751, 2608, ..., 2334, 682, 634, 771] type='100 * ?uint32'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_zipped.seedTracksterIdx[ak.argmax(d_zipped.feature_seedPt, axis=-1, keepdims=True)][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[[True, True, True, True, True, True, ..., False, False, False, False, False],\n",
       " [True, True, True, True, True, True, ..., False, False, False, False, False],\n",
       " [True, True, True, True, True, True, ..., False, False, False, False, False],\n",
       " [False, False, False, False, False, ..., False, False, False, False, False],\n",
       " [True, True, True, True, True, True, ..., False, False, False, False, False],\n",
       " [False, False, False, False, False, ..., False, False, False, False, False],\n",
       " [True, True, True, True, True, True, ..., False, False, False, False, False],\n",
       " [False, False, False, False, False, ..., False, False, False, False, False],\n",
       " [True, True, True, True, True, True, ..., False, False, False, False, False],\n",
       " [False, False, False, False, False, ..., False, False, False, False, False],\n",
       " ...,\n",
       " [True, True, True, True, True, True, ..., False, False, False, False, False],\n",
       " [True, True, True, True, True, True, ..., False, False, False, False, False],\n",
       " [True, True, True, True, True, True, ..., False, False, False, False, False],\n",
       " [True, True, True, True, True, True, ..., False, False, False, False, False],\n",
       " [False, False, False, False, False, ..., False, False, False, False, False],\n",
       " [True, True, True, True, True, True, ..., False, False, False, False, False],\n",
       " [False, False, False, False, False, ..., False, False, False, False, False],\n",
       " [True, True, True, True, True, True, ..., False, False, False, False, False],\n",
       " [True, True, True, True, True, True, ..., False, False, False, False, False]]\n",
       "------------------------------------------------------------------------------\n",
       "type: 100 * var * bool</pre>"
      ],
      "text/plain": [
       "<Array [[True, True, True, ..., False, False], ...] type='100 * var * bool'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.fill_none(d_zipped.seedTracksterIdx == d_zipped.seedTracksterIdx[ak.argmax(d_zipped.feature_seedPt, axis=-1, keepdims=True)][:, 0], [], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[[{seedTracksterIdx: 607, candidateTracksterIdx: 557, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 631, candidateTracksterIdx: 540, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 751, candidateTracksterIdx: 478, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 2608, candidateTracksterIdx: 2405, ...}, ..., {...}],\n",
       " [{seedTracksterIdx: 1966, candidateTracksterIdx: 1992, ...}, ..., {...}],\n",
       " [{seedTracksterIdx: 739, candidateTracksterIdx: 792, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 2052, candidateTracksterIdx: 1762, ...}, ..., {...}],\n",
       " [{seedTracksterIdx: 767, candidateTracksterIdx: 918, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 688, candidateTracksterIdx: 738, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 1875, candidateTracksterIdx: 1638, ...}, ..., {...}],\n",
       " ...,\n",
       " [{seedTracksterIdx: 751, candidateTracksterIdx: 258, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 580, candidateTracksterIdx: 1205, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 527, candidateTracksterIdx: 549, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 1866, candidateTracksterIdx: 1775, ...}, ..., {...}],\n",
       " [{seedTracksterIdx: 737, candidateTracksterIdx: 222, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 2334, candidateTracksterIdx: 1966, ...}, ..., {...}],\n",
       " [{seedTracksterIdx: 682, candidateTracksterIdx: 615, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 634, candidateTracksterIdx: 406, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 771, candidateTracksterIdx: 614, ...}, {...}, ..., {...}]]\n",
       "--------------------------------------------------------------------------------\n",
       "type: 100 * var * inferencePair[\n",
       "    seedTracksterIdx: uint32,\n",
       "    candidateTracksterIdx: uint32,\n",
       "    seedTracksterBestAssociationScore: float32,\n",
       "    seedTracksterBestAssociation_simTsIdx: int64,\n",
       "    candidateTracksterBestAssociationScore: float32,\n",
       "    candidateTracksterBestAssociation_simTsIdx: int64,\n",
       "    candidateTracksterAssociationWithSeed_score: float32,\n",
       "    feature_DeltaEtaBaryc: float32,\n",
       "    feature_DeltaPhiBaryc: float32,\n",
       "    feature_multi_en: float32,\n",
       "    feature_multi_eta: float32,\n",
       "    feature_multi_pt: float32,\n",
       "    feature_seedEta: float32,\n",
       "    feature_seedPhi: float32,\n",
       "    feature_seedEn: float32,\n",
       "    feature_seedPt: float32,\n",
       "    feature_theta: float32,\n",
       "    feature_theta_xz_seedFrame: float32,\n",
       "    feature_theta_yz_seedFrame: float32,\n",
       "    feature_theta_xy_cmsFrame: float32,\n",
       "    feature_theta_yz_cmsFrame: float32,\n",
       "    feature_theta_xz_cmsFrame: float32,\n",
       "    feature_explVar: float32,\n",
       "    feature_explVarRatio: float32\n",
       "]</pre>"
      ],
      "text/plain": [
       "<Array [[{...}, {...}, ..., {...}, {...}], ...] type='100 * var * inference...'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_zipped[ak.fill_none(d_zipped.seedTracksterIdx == d_zipped.seedTracksterIdx[ak.argmax(d_zipped.feature_seedPt, axis=-1, keepdims=True)][:, 0], [], 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[[{seedTracksterIdx: 607, candidateTracksterIdx: 557, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 631, candidateTracksterIdx: 540, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 751, candidateTracksterIdx: 478, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 2608, candidateTracksterIdx: 2405, ...}, ..., {...}],\n",
       " [{seedTracksterIdx: 1966, candidateTracksterIdx: 1992, ...}, ..., {...}],\n",
       " [{seedTracksterIdx: 739, candidateTracksterIdx: 792, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 2052, candidateTracksterIdx: 1762, ...}, ..., {...}],\n",
       " [{seedTracksterIdx: 767, candidateTracksterIdx: 918, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 688, candidateTracksterIdx: 738, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 1875, candidateTracksterIdx: 1638, ...}, ..., {...}],\n",
       " ...,\n",
       " [{seedTracksterIdx: 751, candidateTracksterIdx: 258, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 580, candidateTracksterIdx: 1205, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 527, candidateTracksterIdx: 549, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 1866, candidateTracksterIdx: 1775, ...}, ..., {...}],\n",
       " [{seedTracksterIdx: 737, candidateTracksterIdx: 222, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 2334, candidateTracksterIdx: 1966, ...}, ..., {...}],\n",
       " [{seedTracksterIdx: 682, candidateTracksterIdx: 615, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 634, candidateTracksterIdx: 406, ...}, {...}, ..., {...}],\n",
       " [{seedTracksterIdx: 771, candidateTracksterIdx: 614, ...}, {...}, ..., {...}]]\n",
       "--------------------------------------------------------------------------------\n",
       "type: 100 * var * inferencePair[\n",
       "    seedTracksterIdx: uint32,\n",
       "    candidateTracksterIdx: uint32,\n",
       "    seedTracksterBestAssociationScore: float32,\n",
       "    seedTracksterBestAssociation_simTsIdx: int64,\n",
       "    candidateTracksterBestAssociationScore: float32,\n",
       "    candidateTracksterBestAssociation_simTsIdx: int64,\n",
       "    candidateTracksterAssociationWithSeed_score: float32,\n",
       "    feature_DeltaEtaBaryc: float32,\n",
       "    feature_DeltaPhiBaryc: float32,\n",
       "    feature_multi_en: float32,\n",
       "    feature_multi_eta: float32,\n",
       "    feature_multi_pt: float32,\n",
       "    feature_seedEta: float32,\n",
       "    feature_seedPhi: float32,\n",
       "    feature_seedEn: float32,\n",
       "    feature_seedPt: float32,\n",
       "    feature_theta: float32,\n",
       "    feature_theta_xz_seedFrame: float32,\n",
       "    feature_theta_yz_seedFrame: float32,\n",
       "    feature_theta_xy_cmsFrame: float32,\n",
       "    feature_theta_yz_cmsFrame: float32,\n",
       "    feature_theta_xz_cmsFrame: float32,\n",
       "    feature_explVar: float32,\n",
       "    feature_explVarRatio: float32,\n",
       "    genMatching: bool\n",
       "]</pre>"
      ],
      "text/plain": [
       "<Array [[{...}, {...}, ..., {...}, {...}], ...] type='100 * var * inference...'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt = makeTarget(selectSeedOnly(zipDataset(dataset_ak)))\n",
    "tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015323368136408022"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.mean(tgt.genMatching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00031306191025168794"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.mean(makeTarget(zipDataset(dataset_ak)).genMatching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[[{feature_multi_en: 23.8, feature_multi_eta: -2.87}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 13.5, feature_multi_eta: -2.3}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 8.82, feature_multi_eta: -2.04}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 32.2, feature_multi_eta: 2.97}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 30, feature_multi_eta: 2.65}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 14.1, feature_multi_eta: 2.56}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 31.9, feature_multi_eta: 2.76}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 14.6, feature_multi_eta: 2.23}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 36.9, feature_multi_eta: -2.18}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 37.4, feature_multi_eta: -2.72}, {...}, ..., {...}, {...}],\n",
       " ...,\n",
       " [{feature_multi_en: 4.22, feature_multi_eta: -1.58}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 36.6, feature_multi_eta: -2.53}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 11.3, feature_multi_eta: -2.27}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 6.56, feature_multi_eta: 2.09}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 35.4, feature_multi_eta: 2.83}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 37.6, feature_multi_eta: 2.76}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 6.94, feature_multi_eta: 1.92}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 26.2, feature_multi_eta: -2.7}, {...}, ..., {...}, {...}],\n",
       " [{feature_multi_en: 19, feature_multi_eta: -2.18}, {...}, ..., {...}, {...}]]\n",
       "--------------------------------------------------------------------------------\n",
       "type: 100 * var * {\n",
       "    feature_multi_en: float32,\n",
       "    feature_multi_eta: float32\n",
       "}</pre>"
      ],
      "text/plain": [
       "<Array [[{...}, {...}, ..., {...}, {...}], ...] type='100 * var * {feature_...'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = tgt[[\"feature_multi_en\", \"feature_multi_eta\"]]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArrayType(ListType(RecordType([NumpyType('float32'), NumpyType('float32')], ['feature_multi_en', 'feature_multi_eta'])), 100, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.type(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['DeltaEtaBaryc', 'DeltaPhiBaryc', 'multi_en', 'multi_eta', 'multi_pt', 'seedEta','seedPhi','seedEn', 'seedPt', 'theta', 'theta_xz_seedFrame', 'theta_yz_seedFrame', 'theta_xy_cmsFrame', 'theta_yz_cmsFrame', 'theta_xz_cmsFrame', 'explVar', 'explVarRatio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_ak = [ak.to_numpy(ak.flatten(tgt[\"feature_\" + featName])) for featName in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1881417, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(feats_ak, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4991e-01,  5.2284e-02,  1.6820e-01,  ...,  1.2566e-01,\n",
       "         -2.0207e-02,  9.8886e-02],\n",
       "        [ 1.6956e+00,  1.1760e+00,  5.6003e-01,  ..., -6.7385e-01,\n",
       "          2.1588e+00,  1.8154e+00],\n",
       "        [ 2.3841e+01,  2.6361e+01,  1.2826e+01,  ...,  2.2554e+00,\n",
       "          2.4942e+00,  1.7655e+00],\n",
       "        ...,\n",
       "        [ 2.7881e-01,  5.5533e-02,  2.9864e-01,  ...,  2.4708e-02,\n",
       "          1.1570e-02,  2.6077e-02],\n",
       "        [ 4.4138e+01,  2.5784e+01,  3.4246e+01,  ...,  1.7453e+01,\n",
       "          1.6417e+01,  3.8603e+00],\n",
       "        [ 9.7236e-01,  9.3319e-01,  9.2995e-01,  ...,  9.7565e-01,\n",
       "          9.5715e-01,  9.2568e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([torch.tensor(ar) for ar in feats_ak])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_t = makeTorchDataset(feats_ak, ak.to_numpy(ak.flatten(tgt.genMatching)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(ak.to_numpy(ak.flatten(tgt.genMatching)), dtype=torch.float32)[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([     22,      44,      51,      63,      75,     115,     129,\n",
       "            167,     179,     236,     326,     356,     358,     361,\n",
       "            386,    7459,    7488,    7490,    7493,    7516,   13765,\n",
       "          13788,   13802,   13820,   13898,   21862,   21874,   21892,\n",
       "          21972,   26062,   26101,   26167,   26168,   26170,   42641,\n",
       "          42643,   42991,   48027,   49901,   49913,   49915,   58122,\n",
       "          58124,   73376,   73382,   73432,   73488,   73550,   73567,\n",
       "          73665,   73692,   73729,   73738,   90850,   90881,   90899,\n",
       "          90909,   90923,   90943,   90959,   90987,   91003,   91013,\n",
       "          91126,  105071,  105131,  105155,  105217,  105266,  105312,\n",
       "         105323,  105356,  105387,  105388,  105427,  105434,  105439,\n",
       "         105454,  105462,  105463,  124667,  124684,  124735,  124786,\n",
       "         124913,  124923,  124927,  146473,  146596,  166175,  166229,\n",
       "         166248,  166284,  166286,  182436,  182441,  182445,  204979,\n",
       "         205071,  205312,  205351,  219942,  219978,  219995,  237918,\n",
       "         237956,  237975,  252030,  288018,  288029,  288040,  288110,\n",
       "         288123,  288129,  288185,  300543,  300549,  300604,  303815,\n",
       "         303819,  303861,  303879,  303889,  303895,  303966,  304032,\n",
       "         304041,  304063,  304100,  304106,  304114,  304152,  304171,\n",
       "         304180,  344358,  344413,  344417,  344419,  344961,  361290,\n",
       "         361394,  361413,  361438,  361466,  372067,  372068,  372127,\n",
       "         372135,  372159,  397135,  399303,  399334,  399433,  399448,\n",
       "         399453,  399493,  418022,  418053,  418055,  418070,  465037,\n",
       "         465040,  465300,  478750,  478782,  478810,  478835,  478842,\n",
       "         478933,  478976,  478994,  479011,  479021,  479081,  479086,\n",
       "         479126,  492276,  492307,  492309,  492337,  505700,  505727,\n",
       "         505744,  505783,  505817,  505820,  505881,  505897,  505962,\n",
       "         510254,  510317,  510332,  510396,  528897,  529039,  546695,\n",
       "         546710,  546711,  546724,  546741,  546745,  546783,  546788,\n",
       "         546815,  546861,  546868,  546871,  546876,  546979,  546987,\n",
       "         546989,  547005,  547006,  547023,  547043,  547053,  547076,\n",
       "         561836,  561840,  561875,  561884,  561922,  561930,  569108,\n",
       "         569143,  569151,  569189,  590118,  591203,  591426,  622928,\n",
       "         623049,  623051,  623052,  623073,  623109,  623146,  623163,\n",
       "         623184,  623220,  623257,  623293,  623329,  623367,  634673,\n",
       "         634701,  634747,  634782,  656483,  656501,  656507,  656531,\n",
       "         656536,  662289,  669633,  669637,  691121,  691185,  691219,\n",
       "         691232,  691249,  702326,  702419,  702420,  702481,  702501,\n",
       "         702503,  702520,  702611,  702661,  702663,  702691,  702697,\n",
       "         729095,  729123,  729125,  729152,  729166,  729192,  729199,\n",
       "         743183,  743214,  743220,  744041,  759786,  759808,  759830,\n",
       "         759843,  759867,  770106,  770188,  770217,  770271,  770297,\n",
       "         770308,  770312,  770333,  770343,  770393,  770410,  770436,\n",
       "         770510,  770525,  770544,  786577,  786607,  786621,  786626,\n",
       "         786632,  786660,  786700,  786704,  786720,  786814,  786871,\n",
       "         786873,  786958,  786981,  787010,  808785,  808887,  809033,\n",
       "         809063,  842828,  843028,  843029,  843031,  843034,  843546,\n",
       "         843548,  843551,  846650,  846653,  862668,  862989,  863010,\n",
       "         873124,  873174,  873211,  873249,  873282,  873287,  873301,\n",
       "         873392,  887667,  887755,  901238,  901257,  901343,  901478,\n",
       "         901480,  901492,  901498,  901550,  901580,  901615,  901684,\n",
       "         922025,  922037,  922043,  922063,  922108,  922137,  922183,\n",
       "         930648,  933500,  933508,  933544,  933555,  933573,  933582,\n",
       "         933590,  933611,  933615,  933646,  933654,  935872,  935884,\n",
       "         935890,  935919,  935925,  944594,  944619,  960394,  960511,\n",
       "         960522,  960580,  960603,  976826,  976843,  976866,  976890,\n",
       "         976900,  976977,  976985,  976986,  977040,  977064,  979000,\n",
       "         979023,  979046,  979056,  980841,  980842,  980898,  980921,\n",
       "        1005655, 1005657, 1005682, 1005740, 1005743, 1019893, 1019917,\n",
       "        1046371, 1046387, 1046410, 1046422, 1046510, 1046564, 1046577,\n",
       "        1046588, 1046708, 1046783, 1046803, 1046824, 1066406, 1066436,\n",
       "        1076302, 1102307, 1102334, 1102351, 1102354, 1102414, 1102419,\n",
       "        1102426, 1102458, 1102466, 1102476, 1102515, 1109389, 1109399,\n",
       "        1109410, 1109448, 1115553, 1115561, 1115572, 1115881, 1115892,\n",
       "        1138081, 1138247, 1138383, 1138403, 1138444, 1138472, 1162422,\n",
       "        1162449, 1162472, 1162474, 1162480, 1162502, 1178514, 1178515,\n",
       "        1207221, 1207988, 1208009, 1219888, 1219891, 1219914, 1219922,\n",
       "        1219947, 1219965, 1219969, 1219974, 1220224, 1228667, 1228690,\n",
       "        1228697, 1228722, 1228740, 1233163, 1233208, 1233279, 1233320,\n",
       "        1233372, 1233373, 1251173, 1251246, 1251259, 1251267, 1251269,\n",
       "        1251278, 1251320, 1251414, 1251434, 1251436, 1271208, 1271228,\n",
       "        1271253, 1271257, 1271270, 1271301, 1271360, 1271424, 1271429,\n",
       "        1271503, 1290235, 1290240, 1290251, 1290276, 1290304, 1290326,\n",
       "        1290339, 1290363, 1290396, 1290399, 1293449, 1293482, 1293485,\n",
       "        1327626, 1354661, 1354728, 1354774, 1354776, 1354861, 1354914,\n",
       "        1354957, 1354963, 1354993, 1355006, 1355064, 1355082, 1355092,\n",
       "        1380749, 1380763, 1380777, 1380826, 1380843, 1380892, 1380893,\n",
       "        1380952, 1381007, 1381017, 1399507, 1399561, 1399571, 1454609,\n",
       "        1454621, 1454642, 1468105, 1468127, 1468128, 1468192, 1476843,\n",
       "        1477039, 1495647, 1495664, 1495665, 1495738, 1495745, 1519053,\n",
       "        1531856, 1569850, 1577545, 1577599, 1577611, 1577644, 1577648,\n",
       "        1578231, 1578235, 1608530, 1608581, 1608676, 1608740, 1608803,\n",
       "        1608822, 1608839, 1626707, 1628526, 1628528, 1628532, 1651515,\n",
       "        1651522, 1651557, 1651563, 1651565, 1651576, 1651604, 1651645,\n",
       "        1651693, 1652036, 1652077, 1652126, 1692215, 1692229, 1694081,\n",
       "        1703712, 1728768, 1749535, 1749578, 1762437, 1772577, 1772642,\n",
       "        1772645, 1772666, 1772667, 1772669, 1772718, 1775366, 1775388,\n",
       "        1775389, 1775391, 1775442, 1777532, 1777533, 1777535, 1777585,\n",
       "        1780154, 1780180, 1793747, 1793773, 1803153, 1808402, 1808429,\n",
       "        1808469, 1808496, 1808557, 1808610, 1808627, 1808635, 1808641,\n",
       "        1808646, 1808657, 1808707, 1808717, 1808760, 1808764, 1808768,\n",
       "        1808775, 1808778, 1808803, 1808861, 1808863, 1808881, 1808889,\n",
       "        1827496, 1846752, 1846797, 1846834, 1846867, 1846968, 1846994,\n",
       "        1847017, 1847020, 1847024, 1847097, 1847102, 1861472, 1861485,\n",
       "        1861488, 1861540, 1861541, 1861566, 1861571, 1862097, 1862102,\n",
       "        1869897, 1869901, 1869951]),)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(ak.to_numpy(ak.flatten(tgt.genMatching)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4991e-01,  1.6956e+00,  2.3841e+01, -2.8661e+00,  2.7054e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.1916e+01,  2.8193e-01,\n",
       "          1.3713e-01,  1.3713e-01,  1.8231e+00,  5.3159e-02,  2.7881e-01,\n",
       "          4.4138e+01,  9.7236e-01],\n",
       "        [ 5.2284e-02,  1.1760e+00,  2.6361e+01, -2.7684e+00,  3.2958e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.8218e+01,  1.1699e-01,\n",
       "          7.7512e-03,  7.7512e-03,  6.5022e-01,  1.0302e-01,  5.5533e-02,\n",
       "          2.5784e+01,  9.3319e-01],\n",
       "        [ 1.6820e-01,  5.6003e-01,  1.2826e+01, -2.8844e+00,  1.4293e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.0800e+01,  3.6202e-01,\n",
       "          2.4707e-01,  2.4707e-01,  1.4768e+00,  2.1777e-01,  2.9864e-01,\n",
       "          3.4246e+01,  9.2995e-01],\n",
       "        [-8.6307e-02,  8.1876e-01,  1.6024e+01, -2.6298e+00,  2.2984e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.8261e+01,  3.2822e-01,\n",
       "          1.9353e-01,  1.9353e-01,  1.7767e+00,  9.9170e-02,  3.1675e-01,\n",
       "          3.6538e+01,  9.4272e-01],\n",
       "        [ 1.3327e-01,  5.2146e-01,  3.1260e+01, -2.8494e+00,  3.6064e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.2948e+01,  2.4383e-02,\n",
       "          1.3786e-01,  1.3786e-01,  1.8368e-01,  2.0777e-02,  1.2835e-02,\n",
       "          2.4778e+01,  9.8349e-01],\n",
       "        [ 1.4238e-01,  1.2994e+00,  1.5383e+01, -2.8585e+00,  1.7587e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.2381e+01,  2.8424e-01,\n",
       "          1.6843e-01,  1.6843e-01,  1.4267e+00,  1.5622e-01,  2.4186e-01,\n",
       "          1.7674e+01,  9.4276e-01],\n",
       "        [ 1.5861e-01, -5.5898e-01,  1.1419e+01, -2.8748e+00,  1.2846e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.1383e+01,  3.1228e-01,\n",
       "          3.6940e-01,  3.6940e-01,  1.5214e+00,  3.0488e-01,  8.5544e-02,\n",
       "          1.3543e+01,  9.5923e-01],\n",
       "        [-6.6618e-02,  1.4135e+00,  1.8893e+01, -2.6495e+00,  2.6576e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.6750e+01,  1.2343e-01,\n",
       "          6.9911e-03,  6.9911e-03,  9.3229e-01,  5.9538e-02,  1.0855e-01,\n",
       "          2.3730e+01,  9.6198e-01],\n",
       "        [ 1.2771e-01,  9.7074e-01,  8.5299e+00, -2.8439e+00,  9.8954e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.3296e+01,  2.3395e-01,\n",
       "          7.3805e-02,  7.3805e-02,  7.7593e-01,  2.2577e-01,  6.1975e-02,\n",
       "          1.9286e+01,  9.2155e-01],\n",
       "        [-1.6580e-01,  7.6711e-01,  1.4735e+01, -2.5504e+00,  2.2863e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  8.4660e+01,  1.0256e-01,\n",
       "          1.5924e-02,  1.5924e-02,  6.5198e-01,  8.2009e-02,  6.1662e-02,\n",
       "          3.9296e+01,  9.3475e-01],\n",
       "        [-3.1922e-02, -3.2056e+00,  1.5961e+01, -2.6842e+00,  2.1693e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.4158e+01,  2.8602e-01,\n",
       "          3.7026e-03,  3.7026e-03,  2.8293e+00,  1.3507e-01,  2.5288e-01,\n",
       "          2.9397e+01,  9.8250e-01],\n",
       "        [-9.9356e-02,  6.2599e-01,  1.7555e+01, -2.6168e+00,  2.5507e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.9278e+01,  1.1172e-01,\n",
       "          4.1288e-03,  4.1288e-03,  8.4747e-01,  5.6571e-02,  9.6666e-02,\n",
       "          2.7271e+01,  9.9501e-01],\n",
       "        [-1.0021e-01, -6.8603e-01,  7.3346e+00, -2.6159e+00,  1.0666e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.9344e+01,  2.0072e-01,\n",
       "          2.3997e-01,  2.3997e-01,  2.5132e-01,  5.1510e-02,  1.9647e-01,\n",
       "          3.0234e+01,  9.6009e-01],\n",
       "        [ 6.8204e-02,  3.1806e-01,  1.4009e+01, -2.7844e+00,  1.7240e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.7149e+01,  9.3393e-02,\n",
       "          2.6104e-02,  2.6104e-02,  5.9106e-01,  7.7428e-02,  5.2267e-02,\n",
       "          2.6240e+01,  9.3805e-01],\n",
       "        [-1.0304e-01,  1.8010e+00,  6.4612e+00, -2.6131e+00,  9.4224e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.9567e+01,  4.3952e-01,\n",
       "          2.5956e-01,  2.5956e-01,  2.1478e+00,  3.9059e-02,  4.4045e-01,\n",
       "          1.3500e+01,  9.0211e-01],\n",
       "        [ 1.4913e-01, -6.2052e-01,  1.5609e+01, -2.8653e+00,  1.7726e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.1964e+01,  5.1896e-02,\n",
       "          6.4602e-02,  6.4602e-02,  3.7262e-01,  4.0950e-02,  3.1888e-02,\n",
       "          4.8589e+01,  9.7111e-01],\n",
       "        [ 1.4934e-01,  2.4176e+00,  5.2432e+00, -2.8655e+00,  5.9532e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.1951e+01,  5.1946e-01,\n",
       "          3.0989e-01,  3.0989e-01,  2.2869e+00,  6.0001e-03,  5.2121e-01,\n",
       "          8.0190e+00,  9.3738e-01],\n",
       "        [ 9.2656e-02, -3.3373e+00,  6.5216e+00, -2.8088e+00,  7.8335e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.5538e+01,  4.6054e-01,\n",
       "          7.3584e-02,  7.3584e-02,  2.9134e+00,  3.4082e-01,  3.1900e-01,\n",
       "          2.6437e+01,  9.1980e-01],\n",
       "        [ 1.9126e-01,  3.4398e-01,  1.1329e+01, -2.9074e+00,  1.2338e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  5.9423e+01,  8.2661e-02,\n",
       "          1.9694e-01,  1.9694e-01,  4.3895e-01,  4.2136e-02,  7.1152e-02,\n",
       "          2.2502e+01,  9.9448e-01],\n",
       "        [ 6.3496e-03,  2.1796e+00,  1.1939e+01, -2.7225e+00,  1.5623e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.1397e+01,  2.7527e-01,\n",
       "          7.6025e-02,  7.6025e-02,  2.2524e+00,  4.2187e-02,  2.7253e-01,\n",
       "          1.9014e+01,  9.7938e-01],\n",
       "        [-1.5260e-01,  4.7477e-01,  1.1991e+01, -2.5636e+00,  1.8365e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  8.3563e+01,  8.2999e-02,\n",
       "          4.0057e-02,  4.0057e-02,  4.9988e-01,  7.4415e-02,  3.6842e-02,\n",
       "          2.3273e+01,  9.9142e-01],\n",
       "        [-9.3982e-02,  2.0127e+00,  1.0600e+01, -2.6222e+00,  1.5321e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.8857e+01,  2.7109e-01,\n",
       "          1.0249e-01,  1.0249e-01,  2.0136e+00,  3.2204e-03,  2.7202e-01,\n",
       "          3.3732e+01,  9.5887e-01],\n",
       "        [-1.1431e-01,  4.6313e-02,  4.6590e+00, -2.6018e+00,  6.8704e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  8.0459e+01,  2.9296e-01,\n",
       "          2.6991e-01,  2.6991e-01,  2.0314e-01,  1.1297e-01,  2.7805e-01,\n",
       "          3.5174e+01,  9.1265e-01],\n",
       "        [-1.3404e-01, -3.4935e+00,  9.0918e+00, -2.5821e+00,  1.3671e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  8.2044e+01,  3.2637e-01,\n",
       "          8.9573e-02,  8.9573e-02,  2.4773e+00,  8.0420e-02,  3.1677e-01,\n",
       "          5.2362e+01,  9.7210e-01],\n",
       "        [ 1.1850e-01,  1.9008e+00,  1.0258e+01, -2.8346e+00,  1.2009e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.3878e+01,  2.6201e-01,\n",
       "          1.0520e-01,  1.0520e-01,  1.9048e+00,  2.0994e-02,  2.6234e-01,\n",
       "          2.9327e+01,  9.7714e-01],\n",
       "        [-1.3776e-01, -3.2127e+00,  6.1940e+00, -2.5784e+00,  9.3482e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  8.2347e+01,  4.3599e-01,\n",
       "          9.9086e-02,  9.9086e-02,  2.8034e+00,  1.8138e-01,  3.9911e-01,\n",
       "          3.7928e+01,  9.5591e-01],\n",
       "        [ 9.5977e-02,  2.0970e+00,  2.4083e+01, -2.8121e+00,  2.8832e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.5323e+01,  2.0238e-01,\n",
       "          2.5602e-02,  2.5602e-02,  2.5807e+00,  8.9260e-02,  1.8205e-01,\n",
       "          4.0709e+01,  9.5557e-01],\n",
       "        [ 1.4442e-01, -3.6764e+00,  8.0084e+00, -2.8606e+00,  9.1374e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.2254e+01,  3.6065e-01,\n",
       "          1.7548e-02,  1.7548e-02,  3.1191e+00,  2.1818e-01,  2.8988e-01,\n",
       "          2.5109e+01,  9.4078e-01],\n",
       "        [ 1.2870e-01,  1.9760e+00,  4.2350e+00, -2.8448e+00,  4.9081e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.3234e+01,  4.9493e-01,\n",
       "          3.4877e-01,  3.4877e-01,  1.9604e+00,  1.4333e-01,  4.8355e-01,\n",
       "          1.9029e+01,  9.8775e-01],\n",
       "        [-1.1812e-02,  2.0729e+00,  6.7965e+00, -2.7043e+00,  9.0552e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.2694e+01,  3.6196e-01,\n",
       "          8.1680e-02,  8.1680e-02,  2.6682e+00,  1.2629e-01,  3.4012e-01,\n",
       "          3.3623e+01,  9.4976e-01],\n",
       "        [ 1.7249e-01,  2.4605e+00,  8.7270e+00, -2.8886e+00,  9.6836e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.0542e+01,  3.0867e-01,\n",
       "          3.5224e-02,  3.5224e-02,  2.7176e+00,  1.2447e-01,  2.8319e-01,\n",
       "          2.3668e+01,  9.1960e-01],\n",
       "        [ 1.3561e-01,  9.7135e-02,  1.0225e+01, -2.8518e+00,  1.1769e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.2801e+01,  1.2156e-01,\n",
       "          6.5963e-03,  6.5963e-03,  8.6551e-01,  7.1832e-02,  9.8441e-02,\n",
       "          3.1985e+01,  9.2566e-01],\n",
       "        [-1.6351e-02,  1.9218e+00,  5.4307e+00, -2.6998e+00,  7.2681e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.3022e+01,  2.5779e-01,\n",
       "          1.3493e-01,  1.3493e-01,  1.0949e+00,  2.0450e-01,  1.5988e-01,\n",
       "          1.8239e+01,  9.2834e-01],\n",
       "        [-2.9099e-03,  1.6733e+00,  9.3765e+00, -2.7132e+00,  1.2383e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.2056e+01,  2.8629e-01,\n",
       "          4.7623e-02,  4.7623e-02,  2.5290e+00,  8.9430e-02,  2.7243e-01,\n",
       "          3.1432e+01,  9.4108e-01],\n",
       "        [ 2.8143e-02,  3.6693e-01,  2.0071e+00, -2.7443e+00,  2.5702e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.9871e+01,  8.4070e-01,\n",
       "          6.6825e-01,  6.6825e-01,  1.2153e+00,  7.7562e-01,  4.5148e-01,\n",
       "          1.2178e+00,  1.0000e+00],\n",
       "        [ 1.0619e-01,  2.4726e-01,  1.2040e+01, -2.8223e+00,  1.4269e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.4664e+01,  1.9856e-01,\n",
       "          4.2209e-02,  4.2209e-02,  1.7666e+00,  0.0000e+00,  1.9922e-01,\n",
       "          2.7678e+01,  9.5731e-01],\n",
       "        [ 3.5822e-02,  2.3870e+00,  1.1915e+01, -2.7520e+00,  1.5142e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.9341e+01,  1.9433e-01,\n",
       "          4.2189e-02,  4.2189e-02,  1.7098e+00,  5.2816e-03,  1.9495e-01,\n",
       "          3.1244e+01,  9.5861e-01],\n",
       "        [ 1.8580e-01,  6.2770e-01,  1.3948e+01, -2.9020e+00,  1.5273e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  5.9746e+01,  1.7052e-01,\n",
       "          2.0523e-02,  2.0523e-02,  1.5814e+00,  6.9053e-04,  1.7109e-01,\n",
       "          3.3188e+01,  9.6556e-01],\n",
       "        [ 1.1543e-02,  8.8670e-01,  1.6620e+01, -2.7277e+00,  2.1636e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.1031e+01,  1.8491e-01,\n",
       "          5.4918e-03,  5.4918e-03,  1.9555e+00,  3.7636e-02,  1.8148e-01,\n",
       "          2.2812e+01,  9.4165e-01],\n",
       "        [ 1.9574e-01, -3.5363e+00,  5.7437e+00, -2.9119e+00,  6.2276e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  5.9159e+01,  3.7969e-01,\n",
       "          3.0755e-02,  3.0755e-02,  2.9446e+00,  1.9390e-01,  3.2886e-01,\n",
       "          1.4555e+01,  9.2703e-01],\n",
       "        [-8.9453e-02,  1.1925e+00,  8.4735e+00, -2.6267e+00,  1.2192e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.8505e+01,  7.3038e-02,\n",
       "          4.9425e-02,  4.9425e-02,  4.4989e-01,  6.5883e-02,  3.1621e-02,\n",
       "          3.9986e+01,  9.1586e-01],\n",
       "        [ 2.3468e-02,  1.8103e+00,  9.2793e+00, -2.7396e+00,  1.1938e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.0196e+01,  1.8196e-01,\n",
       "          5.4308e-02,  5.4308e-02,  1.3971e+00,  5.0623e-02,  1.7575e-01,\n",
       "          5.8066e+01,  9.6259e-01],\n",
       "        [-1.7651e-01,  1.4009e+00,  6.3765e+00, -2.5396e+00,  9.9993e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  8.5561e+01,  1.0505e-01,\n",
       "          5.4897e-02,  5.4897e-02,  3.7594e-01,  1.0555e-01,  6.6503e-03,\n",
       "          1.6296e+01,  9.1020e-01],\n",
       "        [-1.3506e-01,  3.7313e-01,  3.7036e+00, -2.5811e+00,  5.5746e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  8.2127e+01,  2.9818e-01,\n",
       "          1.1174e-01,  1.1174e-01,  7.8504e-01,  2.9333e-01,  5.5121e-02,\n",
       "          4.3249e+01,  9.6054e-01],\n",
       "        [ 1.2140e-01,  1.9962e-03,  5.7450e+00, -2.8376e+00,  6.7065e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.3694e+01,  1.7484e-01,\n",
       "          2.8933e-01,  2.8933e-01,  8.1515e-01,  1.1982e-01,  1.2882e-01,\n",
       "          3.2603e+01,  9.1742e-01],\n",
       "        [ 1.0500e-02,  1.0360e+00,  6.6943e+00, -2.7267e+00,  8.7239e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.1104e+01,  8.8580e-02,\n",
       "          6.4691e-02,  6.4691e-02,  3.3615e-01,  8.8971e-02,  5.9902e-03,\n",
       "          4.2970e+01,  9.5017e-01],\n",
       "        [ 5.6475e-02,  1.4589e+00,  8.9083e+00, -2.7726e+00,  1.1092e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.7935e+01,  1.5808e-01,\n",
       "          3.8372e-02,  3.8372e-02,  1.1791e+00,  6.3352e-02,  1.4564e-01,\n",
       "          1.9244e+01,  9.6230e-01],\n",
       "        [ 2.1397e-02, -3.2481e+00,  3.2501e+00, -2.7375e+00,  4.1900e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  7.0340e+01,  5.3209e-01,\n",
       "          1.7964e-01,  1.7964e-01,  2.7544e+00,  1.9628e-01,  4.9885e-01,\n",
       "          1.6661e+01,  9.4509e-01],\n",
       "        [ 1.0726e-01, -3.4179e+00,  1.7014e+01, -2.8234e+00,  2.0143e+00,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.4595e+01,  2.0717e-01,\n",
       "          8.3110e-02,  8.3110e-02,  2.8739e+00,  1.4218e-01,  1.5130e-01,\n",
       "          3.1988e+01,  9.6987e-01],\n",
       "        [ 7.6880e-02, -3.5340e+00,  8.0696e+00, -2.7930e+00,  9.8460e-01,\n",
       "         -2.7162e+00,  6.6292e-01,  5.4562e+02,  6.6573e+01,  2.8849e-01,\n",
       "          1.4526e-02,  1.4526e-02,  2.9603e+00,  1.5396e-01,  2.4494e-01,\n",
       "          2.2546e+01,  9.7183e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_t[0:50][\"features\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_t[0:5][\"genmatching\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Bool but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCELoss()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_t\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenmatching\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/grid_mnt/data_cms_upgrade/cuisset/conda/envs/ticlRegression-gpu/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/grid_mnt/data_cms_upgrade/cuisset/conda/envs/ticlRegression-gpu/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/grid_mnt/data_cms_upgrade/cuisset/conda/envs/ticlRegression-gpu/lib/python3.11/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/grid_mnt/data_cms_upgrade/cuisset/conda/envs/ticlRegression-gpu/lib/python3.11/site-packages/torch/nn/functional.py:3127\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3124\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3125\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Bool but expected Float"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.BCELoss()\n",
    "loss(torch.full((5,), 0.5), ds_t[0:5][\"genmatching\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
